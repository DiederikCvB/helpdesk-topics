{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a093fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267998ff",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ciphix.csv', header=None, names=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0910362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f34f70",
   "metadata": {},
   "source": [
    "# Look around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53170f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"wordcount\"] = df[\"text\"].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8622ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wordcount'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2783c782",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "Looking around I noticed:\n",
    "- all messages start with some kind of username handle\n",
    "- some have multiple username handles\n",
    "- some end with a different tag ^ followed by user acronym\n",
    "- different languages\n",
    "- smileys\n",
    "- URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ae4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check the counts of the first tag mentioned\n",
    "split = df['text'].str.extract(r'(@([a-zA-Z\\d]+)([^\\S\\r\\n]))(.*)')\n",
    "split['text'] = split[3]\n",
    "split['tag'] = split[1]\n",
    "split = split[['tag','text']]\n",
    "split = split.dropna(subset='text')\n",
    "split['tag'].value_counts()[:20].plot(kind='barh', figsize=(10, 8))\n",
    "plt.title(\"Counts of tag first-mentioned\", y=1.02);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b88f9c",
   "metadata": {},
   "source": [
    "# Clean + preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052d82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all @ tags\n",
    "def remove_ats(text):\n",
    "    at_pattern = re.compile('@[a-zA-Z\\d_]+')\n",
    "    return at_pattern.sub(r'', text)\n",
    "\n",
    "#Remove all employee tags\n",
    "#Tags occur at the end of the line with capital letters and prefix '-' or '^'\n",
    "def remove_tag(text):\n",
    "    at_pattern = re.compile('[\\^\\-][A-Z\\d]+$')\n",
    "    return at_pattern.sub(r'', text)\n",
    "\n",
    "#Remove URLS\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "#Remove smileys\n",
    "def remove_emoji(text):   \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                            \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                            \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                            \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                            \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                            \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                            \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                            \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                            \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                            \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                            \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                            \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                            \"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "#Remove newlines.\n",
    "def remove_specialchars(text):\n",
    "    char_pattern = re.compile('[\\n]')\n",
    "    return char_pattern.sub(r'', text)\n",
    "\n",
    "#Remove only non-letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8125ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(remove_ats) \\\n",
    "                                .apply(remove_urls) \\\n",
    "                                .apply(remove_tag) \\\n",
    "                                .apply(remove_emoji) \\\n",
    "                                .apply(remove_specialchars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=25) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2668ae",
   "metadata": {},
   "source": [
    "### Wrapup and count again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c923e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset='clean_text')\n",
    "print(df.shape)\n",
    "df[\"wordcount\"] = df[\"clean_text\"].str.split().str.len()\n",
    "df['wordcount'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9d734",
   "metadata": {},
   "source": [
    "### Inspect special cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a30b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "small = df.loc[df[\"wordcount\"]<2,:].head(n=20)\n",
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeca421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove remaining text not containing letters\n",
    "df = df[~df['clean_text'].str.fullmatch('^[\\s\\d]+$')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"wordcount\"]<2,:].head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4407f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Largest wordcounts seem only a few cases that I accept for now\n",
    "df.loc[df[\"wordcount\"]>65,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f8548",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6183b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
